---
title: 'Safire: Similarity Framework for Visualization Retrieval'
image: nguyen-2025-safire-similarity-framework.png
image-alt: >-
  Overview of the similarity framework for visualization retrieval, providing clear comparison criteria and
  representation modalities.
members:
  - huyen-nguyen
  - nils-gehlenborg
year: 2025
type: preprint
publisher: 'https://osf.io/p47z5'
doi: 10.31219/osf.io/p47z5_v4
cite:
  authors: HN Nguyen and N Gehlenborg
  published: '*2025 IEEE Visualization and Visual Analytics (VIS)*. To appear'
zotero-key: AJ92WHNU
videos: []
other-resources: []
awards: []
---
Effective visualization retrieval necessitates a clear definition of similarity. Despite the growing body of work in specialized visualization retrieval systems, a systematic approach to understanding visualization similarity remains absent. We introduce the Similarity Framework for Visualization Retrieval (Safire), a conceptual model that frames visualization similarity along two dimensions: comparison criteria and representation modalities. Comparison criteria identify the aspects that make visualizations similar, which we divide into primary facets (data, visual encoding, interaction, style, metadata) and derived properties (data-centric and human-centric measures). Safire connects what to compare with how comparisons are executed through representation modalities. We categorize existing representation approaches into four groups based on their levels of information content and visualization determinism: raster image, vector image, specification, and natural language description, together guiding what is computable and comparable. We analyze several visualization retrieval systems using Safire to demonstrate its practical value in clarifying similarity considerations. Our findings reveal how particular criteria and modalities align across different use cases. Notably, the choice of representation modality is not only an implementation detail but also an important decision that shapes retrieval capabilities and limitations. Based on our analysis, we provide recommendations and discuss broader implications for multimodal learning, AI applications, and visualization reproducibility.
